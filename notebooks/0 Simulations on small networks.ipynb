{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import networkx as nx\n",
    "import copy\n",
    "from numba import jit\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def run_urn_model(neigh_dict, rho, nu, N0, APlength, t_max):\n",
    "    t=0\n",
    "    \n",
    "    #creating a common list of concepts which will appear in the adjacent possible\n",
    "    APlist = range(APlength)\n",
    "\n",
    "    #creating Urn dictionaries with\n",
    "    Urn={} #urn elements\n",
    "    Urn_AP_index = 0 \n",
    "    Urn_S={} #sequences of extracted elements\n",
    "    Urn_D={} #set of distinct extracted elements\n",
    "\n",
    "    #Initializing the dictionaries, the key is the node int\n",
    "    for node in neigh_dict.keys():\n",
    "        #initially there are N0 elements, taken from the APlist\n",
    "        Urn[node]=APlist[:N0]\n",
    "        #we still haven't extracted anything from the urns\n",
    "        Urn_S[node]=[] \n",
    "        Urn_D[node]=set()\n",
    "    \n",
    "    #so the moment we have taken the first N0 elements for all the nodes\n",
    "    Urn_AP_index = N0 #index of elements in the APlist\n",
    "    \n",
    "    #Simulation\n",
    "    while t < t_max: #main simulation cycle\n",
    "        if t%2000==0: print ('t', t)\n",
    "        \n",
    "        #All Extractions at once SYNCHRONOUS\n",
    "        extracted_balls={} #temporary dictionary {node: extracted ball at t}\n",
    "        \n",
    "        #print ('EXTRACTIONS')\n",
    "        for node in neigh_dict.keys():\n",
    "            #print ('node', node)\n",
    "            \n",
    "            Social_urn = Urn[node] #the current urn\n",
    "            #plus the others\n",
    "            for nei in neigh_dict[node]:\n",
    "                #summing up the urn of node with the SET of the urns of the neighbors\n",
    "                Social_urn = Social_urn + list(set(Urn[nei]))\n",
    "            \n",
    "            #print ('My urn', Urn[node])\n",
    "            #print ('Social urn', Social_urn)\n",
    "            extracted_ball = np.random.choice(Social_urn)\n",
    "            #print ('extracted ball', extracted_ball)\n",
    "            \n",
    "            #Adding it to the sequence\n",
    "            Urn_S[node].append(extracted_ball)\n",
    "            #Adding it to the temporary dictionary\n",
    "            extracted_balls[node] = extracted_ball\n",
    "\n",
    "        #print ('REINFORCEMENT AND EXPANSION')\n",
    "        for node in neigh_dict.keys():\n",
    "            #print ('node', node)\n",
    "            extracted_ball = extracted_balls[node]\n",
    "            #print ('extracted ball', extracted_ball)\n",
    "            \n",
    "            #REINFORCEMENT: adding rho additional balls of the same color to the urn\n",
    "            Urn[node].extend([extracted_ball] * rho)\n",
    "            #print ('reinforced urn', Urn[node])\n",
    "            \n",
    "            #ADJACENT POSSIBLE\n",
    "            \n",
    "            #if the ball was new (never extracted before)\n",
    "            if extracted_ball not in Urn_D[node]:\n",
    "                Urn_D[node].add(extracted_ball)\n",
    "                #print ('extracted ball is NEW', extracted_ball)\n",
    "                #Adding nu+1 balls to the urn, by using the index on the APlist (different new balls for each urn)\n",
    "                Urn[node].extend(APlist[Urn_AP_index:(Urn_AP_index + (nu+1))])\n",
    "                #updating the index\n",
    "                Urn_AP_index = Urn_AP_index + (nu+1)\n",
    "                #print ('extended urn', Urn[node])\n",
    "        \n",
    "        t += 1\n",
    "        \n",
    "    return Urn_S\n",
    "\n",
    "@jit\n",
    "def get_heap_from_sequence(seq):\n",
    "    unique_balls = set()\n",
    "    heaps_list = []\n",
    "    heaps_list.append(len(unique_balls))\n",
    "    for ball in seq:\n",
    "        unique_balls.add(ball)\n",
    "        heaps_list.append(len(unique_balls))\n",
    "    return heaps_list\n",
    "\n",
    "@jit\n",
    "def run_simulation(neigh_dict, rho, nu, N0, APlength, t_max, iterations):\n",
    "\n",
    "    heaps_mean={}\n",
    "    for node in nodes_list:\n",
    "        heaps_mean[node]=[]\n",
    "\n",
    "    for i in range(iterations):\n",
    "        print ('iteration', i)\n",
    "        Urn_S = run_urn_model(neigh_dict, rho, nu, N0, APlength, t_max)\n",
    "        heaps={}\n",
    "        for node, seq in Urn_S.iteritems():\n",
    "            heaps[node] = get_heap_from_sequence(seq)\n",
    "        for k, v in heaps.iteritems():\n",
    "            heaps_mean[k].append(v)\n",
    "\n",
    "    for node in nodes_list:\n",
    "        heaps_mean[node] = np.array(heaps_mean[node])\n",
    "        heaps_mean[node] = heaps_mean[node].mean(0)\n",
    "\n",
    "    return heaps_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulations for the fourth network of Fig. 3 - this is not in parallel, just for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network\n",
    "G = nx.DiGraph()\n",
    "G.add_edge(0,1)\n",
    "G.add_edge(1,2)\n",
    "G.add_edge(2,3)\n",
    "G.add_edge(1,3)\n",
    "\n",
    "#I don't actually need a G, just the list of neighbors:\n",
    "neigh_dict={n: G[n].keys() for n in G.nodes()}\n",
    "#And the list of nodes\n",
    "nodes_list = [int(n) for n in G.nodes()]\n",
    "del G\n",
    "\n",
    "#Adjacen Possible Concept List\n",
    "APlength = 100000\n",
    "\n",
    "#Urn parameters\n",
    "rho = 6\n",
    "nu = 3\n",
    "N0 = nu + 1 #initial number of distinct elements\n",
    "\n",
    "#Simulation parameters\n",
    "t_max = 10000\n",
    "iterations = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heaps_mean = run_simulation(neigh_dict, rho, nu, N0, APlength, t_max, iterations)\n",
    "\n",
    "import pickle\n",
    "filename=\"../results/Simulations_small_nets/mean_heaps_4nodes_notsym_DIR_rho%inu%i.p\"%(rho, nu)\n",
    "pickle.dump(heaps_mean, open(filename, \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
